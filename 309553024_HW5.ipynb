{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# print(tf.__version__)\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "# print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset \n",
    "https://drive.google.com/drive/u/3/folders/1sHh6NvuKX6RB5OytLwf4kaqfQ9svJNDQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "50000 train samples\n10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(\"x_train.npy\")\n",
    "y_train = np.load(\"y_train.npy\")\n",
    "\n",
    "x_test = np.load(\"x_test.npy\")\n",
    "y_test = np.load(\"y_test.npy\")\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# It's a multi-class classification problem \n",
    "class_index = {'airplane': 0, 'automobile': 1, 'bird': 2, 'cat': 3, 'deer': 4,\n",
    "               'dog': 5, 'frog': 6,'horse': 7,'ship': 8, 'truck': 9}\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://img-blog.csdnimg.cn/20190623084800880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3lqcDE5ODcxMDEz,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert class vectors to one-hot encoding (keras model requires one-hot label as inputs)\n",
    "num_classes = 10\n",
    "print(y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model & training (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build model\n",
    "# model = Sequential() # Sequential groups a linear stack of layers \n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3), input_shape=x_train.shape[1:])) # Add Convolution layers\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(Conv2D(filters=32, kernel_size=(3, 3))) # Add Convolution layers\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(MaxPooling2D(pool_size=(4, 4))) # Add Max pooling to lower the sptail dimension\n",
    "\n",
    "# model.add(Flatten()) # Flatten the featuremaps\n",
    "# model.add(Dense(units=512)) # Add dense layer with 512 neurons\n",
    "# model.add(Activation('relu')) # Add Relu activation for non-linearity\n",
    "# model.add(Dense(units=num_classes)) # Add final output layer for 10 classes\n",
    "# model.add(Activation('softmax')) # Add softmax activation to transfer logits into probabilities\n",
    "\n",
    "# # initiate SGD optimizer\n",
    "# opt = keras.optimizers.SGD()\n",
    "\n",
    "# # Compile the model with loss function and optimizer, and evaluate with accuracy\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# # Setup some hyperparameters\n",
    "# batch_size = 32\n",
    "# epochs = 10\n",
    "\n",
    "# # Fit the data into model\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=epochs,\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build Model\n",
    "# model = Sequential()\n",
    "# model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# model.add(Conv2D(filters=64, kernel_size=3, input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "# # model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# # model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# model.add(Conv2D(filters=128, kernel_size=3, activation='relu', padding='same'))\n",
    "# # model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "\n",
    "# model.add(Flatten()) # Flatten the featuremaps\n",
    "# model.add(Dense(units=512, activation='relu')) # Add dense layer with 512 neurons\n",
    "# model.add(Dense(units=num_classes, activation='softmax')) # Add final output layer for 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 32, 32, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 30, 30, 32)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n_________________________________________________________________\nactivation_3 (Activation)    (None, 15, 15, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n_________________________________________________________________\nactivation_4 (Activation)    (None, 13, 13, 64)        0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 6, 6, 64)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 2304)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               1180160   \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                5130      \n=================================================================\nTotal params: 1,250,858\nTrainable params: 1,250,858\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate SGD optimizer\n",
    "opt = keras.optimizers.SGD()\n",
    "\n",
    "# Compile the model with loss function and optimizer, and evaluate with accuracy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "# Setup some hyperparameters\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "data_augmentation = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Apply data augmentation...\n",
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 2.0934 - accuracy: 0.2226 - val_loss: 1.8063 - val_accuracy: 0.3610\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.7762 - accuracy: 0.3559 - val_loss: 1.6187 - val_accuracy: 0.4111\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.6371 - accuracy: 0.4037 - val_loss: 1.6187 - val_accuracy: 0.4175\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.5271 - accuracy: 0.4418 - val_loss: 1.5066 - val_accuracy: 0.4611\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.4478 - accuracy: 0.4736 - val_loss: 1.3825 - val_accuracy: 0.5127\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.3824 - accuracy: 0.5002 - val_loss: 1.2930 - val_accuracy: 0.5415\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.3292 - accuracy: 0.5226 - val_loss: 1.2588 - val_accuracy: 0.5508\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.2877 - accuracy: 0.5380 - val_loss: 1.2064 - val_accuracy: 0.5705\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.2436 - accuracy: 0.5548 - val_loss: 1.1211 - val_accuracy: 0.6059\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.2069 - accuracy: 0.5697 - val_loss: 1.1441 - val_accuracy: 0.5961\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1683 - accuracy: 0.5825 - val_loss: 1.0403 - val_accuracy: 0.6322\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1353 - accuracy: 0.5939 - val_loss: 1.0347 - val_accuracy: 0.6427\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1008 - accuracy: 0.6075 - val_loss: 0.9806 - val_accuracy: 0.6558\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0673 - accuracy: 0.6206 - val_loss: 0.9662 - val_accuracy: 0.6611\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.0386 - accuracy: 0.6326 - val_loss: 0.9377 - val_accuracy: 0.6700\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.0153 - accuracy: 0.6426 - val_loss: 0.8939 - val_accuracy: 0.6897\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9877 - accuracy: 0.6503 - val_loss: 0.8821 - val_accuracy: 0.6911\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9601 - accuracy: 0.6636 - val_loss: 0.9015 - val_accuracy: 0.6831\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9365 - accuracy: 0.6710 - val_loss: 0.8517 - val_accuracy: 0.7040\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.9149 - accuracy: 0.6773 - val_loss: 0.8835 - val_accuracy: 0.7004\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8964 - accuracy: 0.6860 - val_loss: 0.7998 - val_accuracy: 0.7237\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8749 - accuracy: 0.6929 - val_loss: 0.7685 - val_accuracy: 0.7338\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8637 - accuracy: 0.6977 - val_loss: 0.7665 - val_accuracy: 0.7322\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8425 - accuracy: 0.7038 - val_loss: 0.7728 - val_accuracy: 0.7345\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8330 - accuracy: 0.7093 - val_loss: 0.7817 - val_accuracy: 0.7342\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8157 - accuracy: 0.7151 - val_loss: 0.7300 - val_accuracy: 0.7465\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.8045 - accuracy: 0.7184 - val_loss: 0.7286 - val_accuracy: 0.7436\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7858 - accuracy: 0.7252 - val_loss: 0.7148 - val_accuracy: 0.7516\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7782 - accuracy: 0.7282 - val_loss: 0.6960 - val_accuracy: 0.7585\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.7625 - accuracy: 0.7338 - val_loss: 0.6960 - val_accuracy: 0.7602\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    # Fit the data into model\n",
    "    model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            shuffle=True)\n",
    "else:\n",
    "    print('Apply data augmentation...')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=0.9,\n",
    "        rotation_range=3,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape) # 10000 samples, each sample with probaility of 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argmax(y_pred[0]) # argmax to find the predict class with highest probability. 9=truck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DO NOT MODIFY CODE BELOW!\n",
    "**Please screen shot your results and post it on your report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = your_model.predict(x_test)\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == (10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of my model on test set:  0.7602\n"
     ]
    }
   ],
   "source": [
    "y_test = np.load(\"y_test.npy\")\n",
    "print(\"Accuracy of my model on test set: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3710jvsc74a57bd0198765a982040de57baf703bc332c4e7377147a1ec16ec8a5d13b9392b411682",
   "display_name": "Python 3.7.10 64-bit ('PR': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}